{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "NIck M's Copy of 231_guided-project.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SophistryDude/DS-Unit-2-Applied-Modeling/blob/master/module1-define-ml-problems/NIck_M's_Copy_of_231_guided_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6T1F3qVSBnT"
      },
      "source": [
        "\n",
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 1*\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUfFNAVaSBnV"
      },
      "source": [
        "# Define ML problems\n",
        "- Choose a target to predict, and check its distribution\n",
        "- Avoid leakage of information from test to train or from target to features\n",
        "- Choose an appropriate evaluation metric\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlZUSufrSUVa"
      },
      "source": [
        "### A note in preparation for Unit 3\n",
        "\n",
        "When you're doing your initial data exploration, you're educating yourself about the data, assessing data integrity, and formulating a plan of attack for your predictive model.\n",
        "\n",
        "The best answer to any of these questions may vary from dataset to dataset. *Experiment* with a simple model to help you through the exploratory data analysis phase.\n",
        "\n",
        "#### Meaningful Variation\n",
        "  - Are there any features that are simply constant or quasi-constant values? \n",
        "  - Duplicated features?\n",
        "  - Duplicated rows?\n",
        "  - Are any of your features highly correlated together?\n",
        "    - Linear models can be particularly sensitive to multi-collinearity.\n",
        "    - Larger (esp. wide) datasets tend to have redundant features.\n",
        "\n",
        "#### Categorical Encodings\n",
        "\n",
        "  - What are your high cardinality categories?\n",
        "  - Are there any rare labels that might benefit from grouping together?\n",
        "  - Are there any categories that could be transformed into a meaningful rank (custom ordinal encoding)?\n",
        "\n",
        "#### Distributions\n",
        "\n",
        "  - What are the frequencies of your categorical labels?\n",
        "  - Is your target feature normally distributed? (Assumption for linear regression model)\n",
        "\n",
        "#### Outliers\n",
        "  - How sensitive is your model type to outliers?\n",
        "    - Less sensitive models include tree-based models. \n",
        "    - Linear models, neural networks, and other distance-based models will almost always benefit from scaling.\n",
        "  - What strategy will you use to identify and handle outliers?\n",
        "\n",
        "#### Feature Selection\n",
        "\n",
        "  Why should we reduce the number of features?\n",
        "  - Reduces potential overfitting\n",
        "  - Fewer features -> easier interpretation for your stakeholders.\n",
        "  - Easier implementation and maintain by software engineers.\n",
        "  - Reduced computational resource requirement.\n",
        "\n",
        "#### Reproducibility\n",
        "\n",
        "  - Always set a random seed.\n",
        "  - Comment, comment, comment!\n",
        "  - Print out versions of your software.\n",
        "  - Implement version control for your *data* as well as your *code* (esp. with timestamps!)\n",
        "  - Wrap your code in reproducible functions / classes for modularity of steps, including feature loading, data wrangling, feature processing, etc. (i.e., *use sklearn pipelines!*)\n",
        "  - Combine your modularized functions / classes in a single, centralized pipeline to execute your modularized \n",
        "  - Print out / record your final model parameters (optimized hyperparameter values).\n",
        "  - Record other details of the model: final features passed in, transformations employed, etc.(Jupyter makes this very transparent, but long notebooks can be more confusing than long-form scripts. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNhQLC7tSBnV"
      },
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ4Md7ADSBnW"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BI5uYUASBna"
      },
      "source": [
        "# Choose a target to predict, and check its distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDj8HX-OSBna"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6kZCo_KSBnb"
      },
      "source": [
        "This is the data science process at a high level:\n",
        "\n",
        "<img src=\"https://image.slidesharecdn.com/becomingadatascientistadvice-pydatadc-shared-161012184823/95/becoming-a-data-scientist-advice-from-my-podcast-guests-55-638.jpg?cb=1476298295\">\n",
        "\n",
        "â€”Renee Teate, [Becoming a Data Scientist, PyData DC 2016 Talk](https://www.becomingadatascientist.com/2016/10/11/pydata-dc-2016-talk/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYGRLwNASBnb"
      },
      "source": [
        "We've focused on the 2nd arrow in the diagram, by training predictive models. Now let's zoom out and focus on the 1st arrow: defining problems, by translating business questions into code/data questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRQkSXqESBnc"
      },
      "source": [
        "Last sprint, you did a Kaggle Challenge. Itâ€™s a great way to practice model validation and other technical skills. But that's just part of the modeling process. [Kaggle gets critiqued](https://speakerdeck.com/szilard/machine-learning-software-in-practice-quo-vadis-invited-talk-kdd-conference-applied-data-science-track-august-2017-halifax-canada?slide=119) because some things are done for you: Like [**defining the problem!**](https://www.linkedin.com/pulse/data-science-taught-universities-here-why-maciej-wasiak/) In todayâ€™s module, youâ€™ll begin to practice this objective, with your dataset youâ€™ve chosen for your personal portfolio project.\n",
        "\n",
        "When defining a supervised machine learning problem, one of the first steps is choosing a target to predict."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDLWVPQhSBnc"
      },
      "source": [
        "Which column in your tabular dataset will you predict?\n",
        "\n",
        "Is your problem regression or classification? You have options. Sometimes itâ€™s not straightforward, as we'll see below.\n",
        "\n",
        "- Discrete, ordinal, low cardinality target: Can be regression or multi-class classification.\n",
        "- (In)equality comparison: Converts regression or multi-class classification to binary classification.\n",
        "- Predicted probability: Seems to [blur](https://brohrer.github.io/five_questions_data_science_answers.html) the line between classification and regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGMjpsGMSBnd"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdEBrz_cSBne"
      },
      "source": [
        "Let's reuse the [Burrito reviews dataset.](https://nbviewer.jupyter.org/github/LambdaSchool/DS-Unit-2-Linear-Models/blob/master/module4-logistic-regression/LS_DS_214_assignment.ipynb) ðŸŒ¯\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "MgzYEDJjSBne"
      },
      "source": [
        "import pandas as pd\n",
        "pd.options.display.max_columns = None\n",
        "df = pd.read_csv(DATA_PATH+'burritos/burritos.csv',\n",
        "                 parse_dates=['Date'],\n",
        "                 index_col='Date')"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zmCN3LBSBnh"
      },
      "source": [
        "### Choose your target \n",
        "\n",
        "Which column in your tabular dataset will you predict?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "h_xuZni0SBnh",
        "outputId": "fabf1359-12d0-4c2b-fd98-03d21611600c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location</th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Address</th>\n",
              "      <th>URL</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>overall</th>\n",
              "      <th>Rec</th>\n",
              "      <th>Reviewer</th>\n",
              "      <th>Notes</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-18</th>\n",
              "      <td>Donato's taco shop</td>\n",
              "      <td>California</td>\n",
              "      <td>Miramar</td>\n",
              "      <td>6780 Miramar Rd</td>\n",
              "      <td>http://donatostacoshop.net/</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scott</td>\n",
              "      <td>good fries: 4/5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Oscar's Mexican food</td>\n",
              "      <td>California</td>\n",
              "      <td>San Marcos</td>\n",
              "      <td>225 S Rancho Santa Fe Rd</td>\n",
              "      <td>http://www.yelp.com/biz/oscars-mexican-food-sa...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scott</td>\n",
              "      <td>Fries: 3/5; too little meat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Oscar's Mexican food</td>\n",
              "      <td>Carnitas</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Emily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Oscar's Mexican food</td>\n",
              "      <td>Carne asada</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ricardo</td>\n",
              "      <td>Go to average burrito place like Rigoberto's i...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-27</th>\n",
              "      <td>Pollos Maria</td>\n",
              "      <td>California</td>\n",
              "      <td>Carlsbad</td>\n",
              "      <td>3055 Harding St</td>\n",
              "      <td>http://pollosmaria.com/</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>x</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scott</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Location      Burrito Neighborhood  \\\n",
              "Date                                                         \n",
              "2016-01-18    Donato's taco shop  California       Miramar   \n",
              "2016-01-24  Oscar's Mexican food  California    San Marcos   \n",
              "2016-01-24  Oscar's Mexican food     Carnitas          NaN   \n",
              "2016-01-24  Oscar's Mexican food  Carne asada          NaN   \n",
              "2016-01-27          Pollos Maria   California     Carlsbad   \n",
              "\n",
              "                             Address  \\\n",
              "Date                                   \n",
              "2016-01-18           6780 Miramar Rd   \n",
              "2016-01-24  225 S Rancho Santa Fe Rd   \n",
              "2016-01-24                       NaN   \n",
              "2016-01-24                       NaN   \n",
              "2016-01-27           3055 Harding St   \n",
              "\n",
              "                                                          URL  Yelp  Google  \\\n",
              "Date                                                                          \n",
              "2016-01-18                        http://donatostacoshop.net/   3.5     4.2   \n",
              "2016-01-24  http://www.yelp.com/biz/oscars-mexican-food-sa...   3.5     3.3   \n",
              "2016-01-24                                                NaN   NaN     NaN   \n",
              "2016-01-24                                                NaN   NaN     NaN   \n",
              "2016-01-27                            http://pollosmaria.com/   4.0     3.8   \n",
              "\n",
              "           Chips  Cost  Hunger  Mass (g)  Density (g/mL)  Length  Circum  \\\n",
              "Date                                                                       \n",
              "2016-01-18   NaN  6.49     3.0       NaN             NaN     NaN     NaN   \n",
              "2016-01-24   NaN  5.45     3.5       NaN             NaN     NaN     NaN   \n",
              "2016-01-24   NaN  4.85     1.5       NaN             NaN     NaN     NaN   \n",
              "2016-01-24   NaN  5.25     2.0       NaN             NaN     NaN     NaN   \n",
              "2016-01-27     x  6.59     4.0       NaN             NaN     NaN     NaN   \n",
              "\n",
              "            Volume  Tortilla  Temp  Meat  Fillings  Meat:filling  Uniformity  \\\n",
              "Date                                                                           \n",
              "2016-01-18     NaN       3.0   5.0   3.0       3.5           4.0         4.0   \n",
              "2016-01-24     NaN       2.0   3.5   2.5       2.5           2.0         4.0   \n",
              "2016-01-24     NaN       3.0   2.0   2.5       3.0           4.5         4.0   \n",
              "2016-01-24     NaN       3.0   2.0   3.5       3.0           4.0         5.0   \n",
              "2016-01-27     NaN       4.0   5.0   4.0       3.5           4.5         5.0   \n",
              "\n",
              "            Salsa  Synergy  Wrap  overall  Rec Reviewer  \\\n",
              "Date                                                      \n",
              "2016-01-18    4.0      4.0   4.0     3.80  NaN    Scott   \n",
              "2016-01-24    3.5      2.5   5.0     3.00  NaN    Scott   \n",
              "2016-01-24    3.0      3.0   5.0     3.00  NaN    Emily   \n",
              "2016-01-24    4.0      4.0   5.0     3.75  NaN  Ricardo   \n",
              "2016-01-27    2.5      4.5   4.0     4.20  NaN    Scott   \n",
              "\n",
              "                                                        Notes Unreliable  \\\n",
              "Date                                                                       \n",
              "2016-01-18                                    good fries: 4/5        NaN   \n",
              "2016-01-24                        Fries: 3/5; too little meat        NaN   \n",
              "2016-01-24                                                NaN        NaN   \n",
              "2016-01-24  Go to average burrito place like Rigoberto's i...        NaN   \n",
              "2016-01-27                                                NaN        NaN   \n",
              "\n",
              "           NonSD Beef Pico Guac Cheese Fries Sour cream Pork Chicken Shrimp  \\\n",
              "Date                                                                          \n",
              "2016-01-18   NaN    x    x    x      x     x        NaN  NaN     NaN    NaN   \n",
              "2016-01-24   NaN    x    x    x      x     x        NaN  NaN     NaN    NaN   \n",
              "2016-01-24   NaN  NaN    x    x    NaN   NaN        NaN    x     NaN    NaN   \n",
              "2016-01-24   NaN    x    x    x    NaN   NaN        NaN  NaN     NaN    NaN   \n",
              "2016-01-27   NaN    x    x  NaN      x     x        NaN  NaN     NaN    NaN   \n",
              "\n",
              "           Fish Rice Beans Lettuce Tomato Bell peper Carrots Cabbage Sauce  \\\n",
              "Date                                                                         \n",
              "2016-01-18  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "2016-01-24  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "2016-01-24  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "2016-01-24  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "2016-01-27  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "\n",
              "           Salsa.1 Cilantro Onion Taquito Pineapple  Ham Chile relleno  \\\n",
              "Date                                                                     \n",
              "2016-01-18     NaN      NaN   NaN     NaN       NaN  NaN           NaN   \n",
              "2016-01-24     NaN      NaN   NaN     NaN       NaN  NaN           NaN   \n",
              "2016-01-24     NaN      NaN   NaN     NaN       NaN  NaN           NaN   \n",
              "2016-01-24     NaN      NaN   NaN     NaN       NaN  NaN           NaN   \n",
              "2016-01-27     NaN      NaN   NaN     NaN       NaN  NaN           NaN   \n",
              "\n",
              "           Nopales Lobster  Queso  Egg Mushroom Bacon Sushi Avocado Corn  \\\n",
              "Date                                                                       \n",
              "2016-01-18     NaN     NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN   \n",
              "2016-01-24     NaN     NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN   \n",
              "2016-01-24     NaN     NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN   \n",
              "2016-01-24     NaN     NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN   \n",
              "2016-01-27     NaN     NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN   \n",
              "\n",
              "           Zucchini  \n",
              "Date                 \n",
              "2016-01-18      NaN  \n",
              "2016-01-24      NaN  \n",
              "2016-01-24      NaN  \n",
              "2016-01-24      NaN  \n",
              "2016-01-27      NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HAzNeCglIKT",
        "outputId": "dbdb8a2a-1821-421c-d502-dd7aa51d1ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df['overall'].unique()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.8    , 3.     , 3.75   , 4.2    , 3.2    , 2.6    , 3.9    ,\n",
              "       2.     , 2.5    , 2.75   , 4.1    , 4.     , 3.5    , 4.6    ,\n",
              "       4.5    , 4.25   , 3.4    , 1.     , 3.33333, 3.25   , 4.3    ,\n",
              "       3.3    , 3.6    , 2.8    , 4.4    , 4.7    , 5.     , 1.5    ,\n",
              "       1.8    , 4.9    , 3.7    , 2.9    , 4.8    , 2.7    , 2.3    ,\n",
              "           nan, 2.2    , 2.4    , 3.1    , 2.66   ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ekXLz40ZU1q"
      },
      "source": [
        "# EDA\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWLMhsXPSBnk",
        "outputId": "04a2278a-cddd-4b84-aacf-bb9fd3028d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "df['overall'].describe()"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    421.000000\n",
              "mean       3.620887\n",
              "std        0.755718\n",
              "min        1.000000\n",
              "25%        3.100000\n",
              "50%        3.800000\n",
              "75%        4.100000\n",
              "max        5.000000\n",
              "Name: overall, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjASNdNNfzmP",
        "outputId": "7a6dd17c-ced2-44bb-9eca-789c507eef49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.distplot(df['overall']);\n"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4JBNMVthLBk"
      },
      "source": [
        "#Establishing a baseline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7EOwTdjSBnn"
      },
      "source": [
        "# Avoid leakage of information from test to train or from target to features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlCPs0sASBno"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcTiPb2QSBno"
      },
      "source": [
        "Overfitting is our enemy in applied machine learning, and leakage is often the cause.\n",
        "\n",
        "> Make sure your training features do not contain data from the â€œfutureâ€ (aka time traveling). While this might be easy and obvious in some cases, it can get tricky. â€¦ If your test metric becomes really good all of the sudden, ask yourself what you might be doing wrong. Chances are you are time travelling or overfitting in some way. â€” [Xavier Amatriain](https://www.quora.com/What-are-some-best-practices-for-training-machine-learning-models/answer/Xavier-Amatriain)\n",
        "\n",
        "Choose train, validate, and test sets. Are some observations outliers? Will you exclude them? Will you do a random split or a time-based split? You can (re)read [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6RqM86nSBnp"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pANNxW5SSBnp"
      },
      "source": [
        "First, begin to **explore and clean your data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlQ9YAezeETT"
      },
      "source": [
        "df = pd.read_csv(DATA_PATH+'burritos/burritos.csv')"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPVnjHi1SBnq",
        "outputId": "07332d4d-3d93-4275-b0b5-4a8a83c0098e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df['Burrito'].nunique()"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5y3IJ3iiVIr",
        "outputId": "e89c8349-6cc9-43a8-cfaa-85ed5839f290",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "# What kinds of burritos?\n",
        "df['Burrito'].unique()"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['California ', 'Carnitas', 'Carne asada', 'California',\n",
              "       'combo chicken', 'Monster California', 'Carne Asada',\n",
              "       'Surf & Turf', 'Chile verde pork', 'battered fish ',\n",
              "       'Surf and turf ', 'Adobada ', 'Barbacoa', '2 in 1', 'Adobado',\n",
              "       'Shredded beef', 'Hawaiian', 'Bandido', 'Campeon', 'carne asada',\n",
              "       'California chicken', 'Azteca', 'Lobster', 'Al pastor', 'Custom',\n",
              "       'Machaca', 'Quesaburro', 'Philly ', 'Quesa', 'Surf and turf',\n",
              "       'Mahi', 'Addiction', 'Oaxacalifornia', \"Deborah's special\",\n",
              "       'Chicken nopalito', 'Adobada', 'Chicken', 'California Everything',\n",
              "       'Chile relleno and carnitas', 'California (only cheese)', 'Fish',\n",
              "       'Chimichanga beef', 'Pastor', 'El Hawaiiano ', 'Shrimp',\n",
              "       'El Rusio', 'Bacon breakfast', 'Chile Relleno', 'Bomb', 'Arizona',\n",
              "       'California Burrito', '619 Burrito Original', 'Chicken asada',\n",
              "       'Carne adobada ', 'Bean and cheese', 'Pokirrito classic ',\n",
              "       'Mauna Lani', 'Especial ', 'Ranchero steak', 'Vegetarian',\n",
              "       'Colimas burrito', 'Bean and rice grande size', 'Surf and Turf',\n",
              "       'Bean and Cheese', 'Pollo california', 'California breakfast',\n",
              "       'Baja monster', 'Local', 'Fusion', 'California Surf', 'Super',\n",
              "       'Mixed', 'Carne asada everything', 'Pollo asado', 'Tilapia one',\n",
              "       'Surfin California', 'Nutty', 'Veg Out', 'Veggie',\n",
              "       'California - Steak', 'California - Pork Adobada',\n",
              "       'California - Chicken', 'Holy Moly', 'Barbacoa ',\n",
              "       'California + Guac + sour cream', 'Al Pastor', 'Pollo adobado',\n",
              "       'Asada', 'California Chipotle', \"Dave's California\",\n",
              "       'Chicken and rice', 'Breakfast', 'Fajitas ', 'Tejano',\n",
              "       'Shrimp with guac', 'Bean & cheese', 'Al pastor ',\n",
              "       'Carne asada supreme', 'Cali Diablo', 'Pork california',\n",
              "       'Bitchin California', 'Tijuana', 'Combo chicken',\n",
              "       'Chicken avocado', 'Cabeza', 'Chicken Shawarma', 'Hot cheetos',\n",
              "       'Spicy a la Diabla', 'California everything',\n",
              "       'California everything mini', 'TGunz', 'Al pastor tradicional ',\n",
              "       'Grilled fish salmon', 'Cheese steak', 'California Surf and Turf',\n",
              "       'Shrimp california', 'carne asada ', 'fried fish',\n",
              "       'Steak everything ', 'Golden State', 'Steak fajitas', 'Hashbrown',\n",
              "       'Steak with guacamole', 'Chile Verde (pork)', 'Supreme chicken',\n",
              "       'Carnitas ', 'Alambre california', 'Surfin california',\n",
              "       'Ado-haba california', 'Ala tingada california', 'La Paz',\n",
              "       'Pollo Asado'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kLHp3eEigFl",
        "outputId": "e440b5bf-7ad1-4a8c-81f1-d8b2135f3474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Combine Burrito categories\n",
        "df['Burrito'] = df['Burrito'].str.lower()\n",
        "\n",
        "california = df['Burrito'].str.contains('california')\n",
        "asada = df['Burrito'].str.contains('asada')\n",
        "surf = df['Burrito'].str.contains('surf')\n",
        "carnitas = df['Burrito'].str.contains('carnitas')\n",
        "df = df.drop(columns=['Notes', 'Location', 'Reviewer', 'Address', 'URL', 'Neighborhood'])\n",
        "df.loc[california, 'Burrito'] = 'California'\n",
        "df.loc[asada, 'Burrito'] = 'Asada'\n",
        "df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "df.loc[~california & ~asada & ~surf & ~carnitas, 'Burrito'] = 'Other'\n",
        "\n",
        "df['Burrito'].value_counts()"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "California     170\n",
              "Other          156\n",
              "Asada           43\n",
              "Surf & Turf     29\n",
              "Carnitas        25\n",
              "Name: Burrito, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPoNNKFpj8Oe",
        "outputId": "875af622-b581-4a6d-bd0e-fec069223de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df.isna().sum().sort_values()"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Burrito             0\n",
              "Date                0\n",
              "Tortilla            0\n",
              "Synergy             2\n",
              "Uniformity          2\n",
              "overall             2\n",
              "Hunger              3\n",
              "Wrap                3\n",
              "Fillings            3\n",
              "Cost                7\n",
              "Meat:filling        9\n",
              "Meat               14\n",
              "Temp               20\n",
              "Salsa              25\n",
              "Length            139\n",
              "Volume            141\n",
              "Circum            141\n",
              "Rec               190\n",
              "Beef              243\n",
              "Cheese            263\n",
              "Pico              264\n",
              "Guac              268\n",
              "Fries             295\n",
              "Sour cream        331\n",
              "Google            336\n",
              "Yelp              336\n",
              "Pork              372\n",
              "Sauce             385\n",
              "Rice              387\n",
              "Beans             388\n",
              "Unreliable        390\n",
              "Chips             397\n",
              "Mass (g)          401\n",
              "Density (g/mL)    401\n",
              "Chicken           402\n",
              "Shrimp            402\n",
              "Onion             406\n",
              "Cilantro          408\n",
              "Avocado           410\n",
              "Lettuce           412\n",
              "Cabbage           415\n",
              "Bell peper        416\n",
              "Tomato            416\n",
              "Salsa.1           416\n",
              "NonSD             416\n",
              "Pineapple         416\n",
              "Fish              417\n",
              "Egg               418\n",
              "Chile relleno     419\n",
              "Nopales           419\n",
              "Taquito           419\n",
              "Mushroom          420\n",
              "Bacon             420\n",
              "Corn              420\n",
              "Sushi             421\n",
              "Ham               421\n",
              "Carrots           422\n",
              "Lobster           422\n",
              "Zucchini          422\n",
              "Queso             423\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziYtfGvRSBns"
      },
      "source": [
        "Next, do a **time-based split:**\n",
        "\n",
        "- Train on reviews from 2016 & earlier. \n",
        "- Validate on 2017. \n",
        "- Test on 2018 & later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nSfvVEXklZu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYIBvwzvSBns"
      },
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcjrC1IvSBnk"
      },
      "source": [
        "### How is your target distributed?\n",
        "\n",
        "For a classification problem, determine: How many classes? Are the classes imbalanced?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb35DkvQZT47"
      },
      "source": [
        "df['great'] = (df['overall'] > 4).astype(int)\n",
        "df.drop(columns=['overall', 'Rec'], inplace=True)\n",
        "ohe_cats = df.select_dtypes('object').nunique()\n",
        "ohe_cols = [col for col in ohe_cats.index if ohe_cats[col] <= 2]\n",
        "for col in ohe_cols:\n",
        "  df[col] = df[col].str.lower().apply(lambda x: 1 if x=='x' else 0)\n",
        "thresh = 10\n",
        "unique_cats = df.select_dtypes('object').nunique()\n",
        "high_card_cols = [col for col in unique_cats.index if unique_cats[col] > thresh]\n",
        "df = df.drop(high_card_cols, axis=1)\n",
        "df = df.dropna(axis=1, thresh=400)\n"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMlBw2nakOu_"
      },
      "source": [
        "df = df.fillna('Missing')"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M07B3ThGkmMb"
      },
      "source": [
        "train = df[df['Date'].dt.year < 2017]\n",
        "val = df[df['Date'].dt.year == 2017]\n",
        "test = df[df['Date'].dt.year > 2018]"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vi8wcHKkueP",
        "outputId": "13906eb6-535c-4b27-d7bd-49736b35c0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300, 49), (85, 49), (11, 49))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZggtHwChQoU",
        "outputId": "c5401d49-3906-4f4e-bec4-dee8a98f832b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target = 'great'\n",
        "y = df[target]\n",
        "X = df.drop(target, axis=1)\n",
        "print('Number of classes:', y.nunique())"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of classes: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzW3G23_hWba",
        "outputId": "83316b5f-bdd8-4d62-afe5-ebde1e65e970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y.value_counts(normalize=True)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.744681\n",
              "1    0.255319\n",
              "Name: great, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWwgDe-9hWb5",
        "outputId": "f72477d7-2bf2-4fde-aa2e-85d7f3a02e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Date</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>great</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>California</td>\n",
              "      <td>2016-01-18</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>California</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Asada</td>\n",
              "      <td>2016-01-24</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>California</td>\n",
              "      <td>2016-01-27</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Burrito       Date  Cost Hunger  Tortilla Temp Meat Fillings  \\\n",
              "0  California 2016-01-18  6.49      3       3.0    5    3      3.5   \n",
              "1  California 2016-01-24  5.45    3.5       2.0  3.5  2.5      2.5   \n",
              "2    Carnitas 2016-01-24  4.85    1.5       3.0    2  2.5        3   \n",
              "3       Asada 2016-01-24  5.25      2       3.0    2  3.5        3   \n",
              "4  California 2016-01-27  6.59      4       4.0    5    4      3.5   \n",
              "\n",
              "  Meat:filling Uniformity Synergy Wrap  Unreliable  NonSD  Beef  Pico  Guac  \\\n",
              "0            4          4       4    4           0      0     1     1     1   \n",
              "1            2          4     2.5    5           0      0     1     1     1   \n",
              "2          4.5          4       3    5           0      0     0     1     1   \n",
              "3            4          5       4    5           0      0     1     1     1   \n",
              "4          4.5          5     4.5    4           0      0     1     1     0   \n",
              "\n",
              "   Cheese  Fries  Sour cream  Pork  Chicken  Shrimp  Fish  Rice  Beans  \\\n",
              "0       1      1           0     0        0       0     0     0      0   \n",
              "1       1      1           0     0        0       0     0     0      0   \n",
              "2       0      0           0     1        0       0     0     0      0   \n",
              "3       0      0           0     0        0       0     0     0      0   \n",
              "4       1      1           0     0        0       0     0     0      0   \n",
              "\n",
              "   Lettuce  Tomato  Bell peper  Carrots  Cabbage  Sauce  Salsa.1  Cilantro  \\\n",
              "0        0       0           0        0        0      0        0         0   \n",
              "1        0       0           0        0        0      0        0         0   \n",
              "2        0       0           0        0        0      0        0         0   \n",
              "3        0       0           0        0        0      0        0         0   \n",
              "4        0       0           0        0        0      0        0         0   \n",
              "\n",
              "   Onion  Taquito  Pineapple  Ham  Chile relleno  Nopales  Lobster  Egg  \\\n",
              "0      0        0          0    0              0        0        0    0   \n",
              "1      0        0          0    0              0        0        0    0   \n",
              "2      0        0          0    0              0        0        0    0   \n",
              "3      0        0          0    0              0        0        0    0   \n",
              "4      0        0          0    0              0        0        0    0   \n",
              "\n",
              "   Mushroom  Bacon  Sushi  Avocado  Corn  Zucchini  great  \n",
              "0         0      0      0        0     0         0      0  \n",
              "1         0      0      0        0     0         0      0  \n",
              "2         0      0      0        0     0         0      0  \n",
              "3         0      0      0        0     0         0      0  \n",
              "4         0      0      0        0     0         0      1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JsMqkJsSBnu"
      },
      "source": [
        "Begin to choose which features, if any, to exclude. **Would some features â€œleakâ€ future information?**\n",
        "\n",
        "What happens if we _DONâ€™T_ drop features with leakage?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2R7zUoDSBnv",
        "outputId": "dafc43e1-2c47-4564-a17c-ee44f09d7274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Try a shallow decision tree as a fast, first model\n",
        "\n",
        "import category_encoders as ce\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "target = 'great'\n",
        "features = train.columns.drop([target, 'Date'])\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    DecisionTreeClassifier(max_depth=3)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7411764705882353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB8USB5ylR2X",
        "outputId": "d5f6ae98-8b21-45d4-8c45-1b076c6c84ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "source": [
        "# This score is too good to be true.\n",
        "# Visualize the decision tree, to see what the model \"learned\"\n",
        "\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "tree = pipeline.named_steps['decisiontreeclassifier']\n",
        "\n",
        "dot_data = export_graphviz(\n",
        "    tree, \n",
        "    out_file=None, \n",
        "    feature_names=X_train.columns, \n",
        "    class_names=y_train.unique().astype(str), \n",
        "    filled=True, \n",
        "    impurity=False,\n",
        "    proportion=True\n",
        ")\n",
        "\n",
        "graphviz.Source(dot_data)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f0d9798d4a8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"897pt\" height=\"373pt\"\n viewBox=\"0.00 0.00 897.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 893,-369 893,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#eda978\" stroke=\"#000000\" points=\"480.5,-365 348.5,-365 348.5,-297 480.5,-297 480.5,-365\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Fillings &lt;= 4.5</text>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100.0%</text>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.76, 0.24]</text>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#e68641\" stroke=\"#000000\" points=\"405.5,-261 273.5,-261 273.5,-193 405.5,-193 405.5,-261\"/>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Fillings &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50.0%</text>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.96, 0.04]</text>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M389.9422,-296.9465C383.5968,-288.1475 376.6879,-278.5672 370.0764,-269.3993\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"372.8011,-267.1937 364.113,-261.13 367.1234,-271.2882 372.8011,-267.1937\"/>\n<text text-anchor=\"middle\" x=\"360.1148\" y=\"-282.1082\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#f9e4d5\" stroke=\"#000000\" points=\"555.5,-261 423.5,-261 423.5,-193 555.5,-193 555.5,-261\"/>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Meat &lt;= 3.5</text>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50.0%</text>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.56, 0.44]</text>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 0&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>0&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M439.0578,-296.9465C445.4032,-288.1475 452.3121,-278.5672 458.9236,-269.3993\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"461.8766,-271.2882 464.887,-261.13 456.1989,-267.1937 461.8766,-271.2882\"/>\n<text text-anchor=\"middle\" x=\"468.8852\" y=\"-282.1082\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#e99457\" stroke=\"#000000\" points=\"263,-157 116,-157 116,-89 263,-89 263,-157\"/>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Tortilla &lt;= 3.9</text>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15.0%</text>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.867, 0.133]</text>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M290.3844,-192.9465C276.5281,-183.3395 261.3283,-172.8009 247.0261,-162.8848\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"248.9382,-159.9515 238.726,-157.13 244.9497,-165.7041 248.9382,-159.9515\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#e58139\" stroke=\"#000000\" points=\"398,-149.5 281,-149.5 281,-96.5 398,-96.5 398,-149.5\"/>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 35.0%</text>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M339.5,-192.9465C339.5,-182.2621 339.5,-170.4254 339.5,-159.5742\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"343.0001,-159.5421 339.5,-149.5422 336.0001,-159.5422 343.0001,-159.5421\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#e58139\" stroke=\"#000000\" points=\"117,-53 0,-53 0,0 117,0 117,-53\"/>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 10.0%</text>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M143.3143,-88.9777C130.2621,-79.3629 116.0861,-68.9203 103.1273,-59.3743\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"104.9386,-56.3615 94.8114,-53.2485 100.7869,-61.9974 104.9386,-56.3615\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#f6d5bd\" stroke=\"#000000\" points=\"252,-53 135,-53 135,0 252,0 252,-53\"/>\n<text text-anchor=\"middle\" x=\"193.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5.0%</text>\n<text text-anchor=\"middle\" x=\"193.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.6, 0.4]</text>\n<text text-anchor=\"middle\" x=\"193.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.9103,-88.9777C191.2519,-80.7364 191.6187,-71.887 191.9657,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"195.474,-63.3849 192.3913,-53.2485 188.48,-63.0949 195.474,-63.3849\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#e88e4d\" stroke=\"#000000\" points=\"563,-157 416,-157 416,-89 563,-89 563,-157\"/>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Burrito &lt;= 4.5</text>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14.7%</text>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.909, 0.091]</text>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M489.5,-192.9465C489.5,-184.776 489.5,-175.9318 489.5,-167.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"493.0001,-167.13 489.5,-157.13 486.0001,-167.13 493.0001,-167.13\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#c6e3f7\" stroke=\"#000000\" points=\"728,-157 581,-157 581,-89 728,-89 728,-157\"/>\n<text text-anchor=\"middle\" x=\"654.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Synergy &lt;= 3.5</text>\n<text text-anchor=\"middle\" x=\"654.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 35.3%</text>\n<text text-anchor=\"middle\" x=\"654.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.415, 0.585]</text>\n<text text-anchor=\"middle\" x=\"654.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 6&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>6&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M543.5272,-192.9465C558.9115,-183.2497 575.8016,-172.6039 591.6621,-162.6069\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"593.758,-165.4232 600.3514,-157.13 590.0254,-159.5013 593.758,-165.4232\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#e78a48\" stroke=\"#000000\" points=\"416.5,-53 284.5,-53 284.5,0 416.5,0 416.5,-53\"/>\n<text text-anchor=\"middle\" x=\"350.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14.3%</text>\n<text text-anchor=\"middle\" x=\"350.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.93, 0.07]</text>\n<text text-anchor=\"middle\" x=\"350.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M440.4938,-88.9777C426.5126,-79.2713 411.3162,-68.7213 397.4602,-59.1018\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"399.2394,-56.0763 389.0289,-53.2485 395.2474,-61.8264 399.2394,-56.0763\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#399de5\" stroke=\"#000000\" points=\"552,-53 435,-53 435,0 552,0 552,-53\"/>\n<text text-anchor=\"middle\" x=\"493.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 0.3%</text>\n<text text-anchor=\"middle\" x=\"493.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.0, 1.0]</text>\n<text text-anchor=\"middle\" x=\"493.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 7&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>7&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M490.9103,-88.9777C491.2519,-80.7364 491.6187,-71.887 491.9657,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"495.474,-63.3849 492.3913,-53.2485 488.48,-63.0949 495.474,-63.3849\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#f4c9aa\" stroke=\"#000000\" points=\"724,-53 577,-53 577,0 724,0 724,-53\"/>\n<text text-anchor=\"middle\" x=\"650.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14.7%</text>\n<text text-anchor=\"middle\" x=\"650.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.636, 0.364]</text>\n<text text-anchor=\"middle\" x=\"650.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M653.0897,-88.9777C652.7481,-80.7364 652.3813,-71.887 652.0343,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"655.52,-63.0949 651.6087,-53.2485 648.526,-63.3849 655.52,-63.0949\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#7ebfee\" stroke=\"#000000\" points=\"889,-53 742,-53 742,0 889,0 889,-53\"/>\n<text text-anchor=\"middle\" x=\"815.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 20.7%</text>\n<text text-anchor=\"middle\" x=\"815.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.258, 0.742]</text>\n<text text-anchor=\"middle\" x=\"815.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M711.2626,-88.9777C727.8386,-79.0424 745.8893,-68.2232 762.2402,-58.4228\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"764.3511,-61.2382 771.129,-53.095 760.7523,-55.2341 764.3511,-61.2382\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k78Nb7O8SBnx"
      },
      "source": [
        "Drop the column with â€œleakageâ€."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6LXD17PSBny",
        "outputId": "61a5b675-c4b4-4eb6-abea-5968701db156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "features = train.columns.drop([target, 'Date'])\n",
        "\n",
        "X_train = train[features]\n",
        "X_val = val[features]\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    DecisionTreeClassifier(max_depth=3)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7411764705882353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGIxRTCMlzXs",
        "outputId": "49fa216c-40bf-485e-d4b9-4d1d67c11a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "source": [
        "\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "tree = pipeline.named_steps['decisiontreeclassifier']\n",
        "\n",
        "dot_data = export_graphviz(\n",
        "    tree, \n",
        "    out_file=None, \n",
        "    feature_names=X_train.columns, \n",
        "    class_names=y_train.unique().astype(str), \n",
        "    filled=True, \n",
        "    impurity=False,\n",
        "    proportion=True\n",
        ")\n",
        "\n",
        "graphviz.Source(dot_data)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f0d96050390>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"897pt\" height=\"373pt\"\n viewBox=\"0.00 0.00 897.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 893,-369 893,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#eda978\" stroke=\"#000000\" points=\"480.5,-365 348.5,-365 348.5,-297 480.5,-297 480.5,-365\"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Fillings &lt;= 4.5</text>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100.0%</text>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.76, 0.24]</text>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#e68641\" stroke=\"#000000\" points=\"405.5,-261 273.5,-261 273.5,-193 405.5,-193 405.5,-261\"/>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Fillings &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50.0%</text>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.96, 0.04]</text>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M389.9422,-296.9465C383.5968,-288.1475 376.6879,-278.5672 370.0764,-269.3993\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"372.8011,-267.1937 364.113,-261.13 367.1234,-271.2882 372.8011,-267.1937\"/>\n<text text-anchor=\"middle\" x=\"360.1148\" y=\"-282.1082\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#f9e4d5\" stroke=\"#000000\" points=\"555.5,-261 423.5,-261 423.5,-193 555.5,-193 555.5,-261\"/>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Meat &lt;= 3.5</text>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50.0%</text>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.56, 0.44]</text>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 0&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>0&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M439.0578,-296.9465C445.4032,-288.1475 452.3121,-278.5672 458.9236,-269.3993\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"461.8766,-271.2882 464.887,-261.13 456.1989,-267.1937 461.8766,-271.2882\"/>\n<text text-anchor=\"middle\" x=\"468.8852\" y=\"-282.1082\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#e99457\" stroke=\"#000000\" points=\"263,-157 116,-157 116,-89 263,-89 263,-157\"/>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Tortilla &lt;= 3.9</text>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15.0%</text>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.867, 0.133]</text>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M290.3844,-192.9465C276.5281,-183.3395 261.3283,-172.8009 247.0261,-162.8848\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"248.9382,-159.9515 238.726,-157.13 244.9497,-165.7041 248.9382,-159.9515\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#e58139\" stroke=\"#000000\" points=\"398,-149.5 281,-149.5 281,-96.5 398,-96.5 398,-149.5\"/>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 35.0%</text>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"339.5\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M339.5,-192.9465C339.5,-182.2621 339.5,-170.4254 339.5,-159.5742\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"343.0001,-159.5421 339.5,-149.5422 336.0001,-159.5422 343.0001,-159.5421\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#e58139\" stroke=\"#000000\" points=\"117,-53 0,-53 0,0 117,0 117,-53\"/>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 10.0%</text>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M143.3143,-88.9777C130.2621,-79.3629 116.0861,-68.9203 103.1273,-59.3743\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"104.9386,-56.3615 94.8114,-53.2485 100.7869,-61.9974 104.9386,-56.3615\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#f6d5bd\" stroke=\"#000000\" points=\"252,-53 135,-53 135,0 252,0 252,-53\"/>\n<text text-anchor=\"middle\" x=\"193.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5.0%</text>\n<text text-anchor=\"middle\" x=\"193.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.6, 0.4]</text>\n<text text-anchor=\"middle\" x=\"193.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.9103,-88.9777C191.2519,-80.7364 191.6187,-71.887 191.9657,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"195.474,-63.3849 192.3913,-53.2485 188.48,-63.0949 195.474,-63.3849\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#e88e4d\" stroke=\"#000000\" points=\"563,-157 416,-157 416,-89 563,-89 563,-157\"/>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Burrito &lt;= 4.5</text>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14.7%</text>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.909, 0.091]</text>\n<text text-anchor=\"middle\" x=\"489.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M489.5,-192.9465C489.5,-184.776 489.5,-175.9318 489.5,-167.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"493.0001,-167.13 489.5,-157.13 486.0001,-167.13 493.0001,-167.13\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#c6e3f7\" stroke=\"#000000\" points=\"728,-157 581,-157 581,-89 728,-89 728,-157\"/>\n<text text-anchor=\"middle\" x=\"654.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Synergy &lt;= 3.5</text>\n<text text-anchor=\"middle\" x=\"654.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 35.3%</text>\n<text text-anchor=\"middle\" x=\"654.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.415, 0.585]</text>\n<text text-anchor=\"middle\" x=\"654.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 6&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>6&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M543.5272,-192.9465C558.9115,-183.2497 575.8016,-172.6039 591.6621,-162.6069\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"593.758,-165.4232 600.3514,-157.13 590.0254,-159.5013 593.758,-165.4232\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#e78a48\" stroke=\"#000000\" points=\"416.5,-53 284.5,-53 284.5,0 416.5,0 416.5,-53\"/>\n<text text-anchor=\"middle\" x=\"350.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14.3%</text>\n<text text-anchor=\"middle\" x=\"350.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.93, 0.07]</text>\n<text text-anchor=\"middle\" x=\"350.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M440.4938,-88.9777C426.5126,-79.2713 411.3162,-68.7213 397.4602,-59.1018\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"399.2394,-56.0763 389.0289,-53.2485 395.2474,-61.8264 399.2394,-56.0763\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#399de5\" stroke=\"#000000\" points=\"552,-53 435,-53 435,0 552,0 552,-53\"/>\n<text text-anchor=\"middle\" x=\"493.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 0.3%</text>\n<text text-anchor=\"middle\" x=\"493.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.0, 1.0]</text>\n<text text-anchor=\"middle\" x=\"493.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 7&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>7&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M490.9103,-88.9777C491.2519,-80.7364 491.6187,-71.887 491.9657,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"495.474,-63.3849 492.3913,-53.2485 488.48,-63.0949 495.474,-63.3849\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#f4c9aa\" stroke=\"#000000\" points=\"724,-53 577,-53 577,0 724,0 724,-53\"/>\n<text text-anchor=\"middle\" x=\"650.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14.7%</text>\n<text text-anchor=\"middle\" x=\"650.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.636, 0.364]</text>\n<text text-anchor=\"middle\" x=\"650.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M653.0897,-88.9777C652.7481,-80.7364 652.3813,-71.887 652.0343,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"655.52,-63.0949 651.6087,-53.2485 648.526,-63.3849 655.52,-63.0949\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#7ebfee\" stroke=\"#000000\" points=\"889,-53 742,-53 742,0 889,0 889,-53\"/>\n<text text-anchor=\"middle\" x=\"815.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 20.7%</text>\n<text text-anchor=\"middle\" x=\"815.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.258, 0.742]</text>\n<text text-anchor=\"middle\" x=\"815.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M711.2626,-88.9777C727.8386,-79.0424 745.8893,-68.2232 762.2402,-58.4228\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"764.3511,-61.2382 771.129,-53.095 760.7523,-55.2341 764.3511,-61.2382\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QA8wPcuSBn0"
      },
      "source": [
        "# Choose an appropriate evaluation metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7KOY3mmSBn1"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpX8a_juSBn2"
      },
      "source": [
        "How will you evaluate success for your predictive model? You must choose an appropriate evaluation metric, depending on the context and constraints of your problem.\n",
        "\n",
        "**Classification & regression metrics are different!**\n",
        "\n",
        "- Donâ€™t use _regression_ metrics to evaluate _classification_ tasks.\n",
        "- Donâ€™t use _classification_ metrics to evaluate _regression_ tasks.\n",
        "\n",
        "[Scikit-learn has lists of popular metrics.](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Ah0zkQSBn2"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1ZOKoZ1SBn3"
      },
      "source": [
        "For classification problems: \n",
        "\n",
        "As a rough rule of thumb, if your majority class frequency is >= 50% and < 70% then you can just use accuracy if you want. Outside that range, accuracy could be misleading â€” so what evaluation metric will you choose, in addition to or instead of accuracy? For example:\n",
        "\n",
        "- Precision?\n",
        "- Recall?\n",
        "- ROC AUC?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHJy1iz9SBn3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w71gRiYzSBn5"
      },
      "source": [
        "### Precision & Recall\n",
        "\n",
        "Let's review Precision & Recall. What do these metrics mean, in scenarios like these?\n",
        "\n",
        "- Predict great burritos\n",
        "- Predict fraudulent transactions\n",
        "- Recommend Spotify songs\n",
        "\n",
        "[Are false positives or false negatives more costly? Can you optimize for dollars?](https://alexgude.com/blog/machine-learning-metrics-interview/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XqqI-3YSBn5"
      },
      "source": [
        "### ROC AUC \n",
        "\n",
        "Let's also review ROC AUC (Receiver Operating Characteristic, Area Under the Curve).\n",
        "\n",
        "[Wikipedia explains,](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) \"A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. **The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.**\"\n",
        "\n",
        "ROC AUC is the area under the ROC curve. [It can be interpreted](https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it) as \"the expectation that a uniformly drawn random positive is ranked before a uniformly drawn random negative.\" \n",
        "\n",
        "ROC AUC measures **how well a classifier ranks predicted probabilities.** So, when you get your classifierâ€™s ROC AUC score, you need to **use predicted probabilities, not discrete predictions.**\n",
        "\n",
        "ROC AUC ranges **from 0 to 1.** Higher is better. A naive majority class **baseline** will have an ROC AUC score of **0.5**, regardless of class (im)balance.\n",
        "\n",
        "#### Scikit-Learn docs\n",
        "- [User Guide: Receiver operating characteristic (ROC)](https://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc)\n",
        "- [sklearn.metrics.roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)\n",
        "- [sklearn.metrics.roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
        "\n",
        "#### More links\n",
        "- [StatQuest video](https://youtu.be/4jRBRDbJemM)\n",
        "- [Data School article / video](https://www.dataschool.io/roc-curves-and-auc-explained/)\n",
        "- [The philosophical argument for using ROC curves](https://lukeoakdenrayner.wordpress.com/2018/01/07/the-philosophical-argument-for-using-roc-curves/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1FYFsINSBn6",
        "outputId": "110f5728-0f64-4d62-c9a4-b017073f7648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_pred_probab = pipeline.predict_proba(X_val)[:, -1]\n",
        "roc_auc_score(y_val, y_pred_probab)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7536666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO8HD-0SpoQo",
        "outputId": "93d74b01-8e96-4aad-dbab-b749523eb648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_probab)\n",
        "\n",
        "pd.DataFrame({\n",
        "  'False Positive Rate': fpr,\n",
        "  'True Positive Rate': tpr,\n",
        "  'Threshold': thresholds          \n",
        "})"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>True Positive Rate</th>\n",
              "      <th>Threshold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.741935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.741935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.316667</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.383333</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.069767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   False Positive Rate  True Positive Rate  Threshold\n",
              "0             0.000000                0.00   1.741935\n",
              "1             0.083333                0.32   0.741935\n",
              "2             0.250000                0.44   0.400000\n",
              "3             0.316667                0.80   0.363636\n",
              "4             0.383333                0.88   0.069767\n",
              "5             1.000000                1.00   0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VF-i89dqDZg",
        "outputId": "995e85c0-b1ba-4c29-d535-bfc23fb10abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# See the results on a plot.\n",
        "# This is the \"Receiver Operating Characteristic curve\"\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(fpr, tpr)\n",
        "plt.plot(fpr, tpr)\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate');"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypz1bOmsSBn8"
      },
      "source": [
        "### Imbalanced classes\n",
        "\n",
        "Do you have highly imbalanced classes?\n",
        "\n",
        "If so, you can try ideas from [Learning from Imbalanced Classes](https://www.svds.com/tbt-learning-imbalanced-classes/):\n",
        "\n",
        "- â€œAdjust the class weight (misclassification costs)â€ â€” most scikit-learn classifiers have a `class_balance` parameter.\n",
        "- â€œAdjust the decision thresholdâ€ â€” we did this last module. Read [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415).\n",
        "- â€œOversample the minority class, undersample the majority class, or synthesize new minority classesâ€ â€” try the the [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library as a stretch goal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSdc7NV0SBn8"
      },
      "source": [
        "# BONUS: Regression example ðŸ˜ï¸\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "YIsk5eyLSBn9"
      },
      "source": [
        "# Read our NYC apartment rental listing dataset\n",
        "df = pd.read_csv(DATA_PATH+'apartments/renthop-nyc.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PmtqWaXSBn_"
      },
      "source": [
        "### Choose your target\n",
        "\n",
        "Which column in your tabular dataset will you predict?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "AeH6s56xSBn_"
      },
      "source": [
        "y = df['price']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rR1Z1zLSBoB"
      },
      "source": [
        "### How is your target distributed?\n",
        "\n",
        "For a regression problem, determine: Is the target right-skewed?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "cKoR7XNmSBoC"
      },
      "source": [
        "# Yes, the target is right-skewed\n",
        "import seaborn as sns\n",
        "sns.distplot(y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E30pITmSBoE"
      },
      "source": [
        "y.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMTchmetSBoG"
      },
      "source": [
        "### Are some observations outliers? \n",
        "\n",
        "Will you exclude\n",
        "them?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "zmnS8xm2SBoG"
      },
      "source": [
        "# Yes! There are outliers\n",
        "# Some prices are so high or low it doesn't really make sense.\n",
        "# Some locations aren't even in New York City\n",
        "\n",
        "# Remove the most extreme 1% prices, \n",
        "# the most extreme .1% latitudes, &\n",
        "# the most extreme .1% longitudes\n",
        "import numpy as np\n",
        "df = df[(df['price'] >= np.percentile(df['price'], 0.5)) & \n",
        "        (df['price'] <= np.percentile(df['price'], 99.5)) & \n",
        "        (df['latitude'] >= np.percentile(df['latitude'], 0.05)) & \n",
        "        (df['latitude'] < np.percentile(df['latitude'], 99.95)) &\n",
        "        (df['longitude'] >= np.percentile(df['longitude'], 0.05)) & \n",
        "        (df['longitude'] <= np.percentile(df['longitude'], 99.95))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2PGMCwlSBoI"
      },
      "source": [
        "# The distribution has improved, but is still right-skewed\n",
        "y = df['price']\n",
        "sns.distplot(y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUyjos_fSBoJ"
      },
      "source": [
        "y.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zndtY_HUSBoL"
      },
      "source": [
        "### Log-Transform\n",
        "\n",
        "If the target is right-skewed, you may want to â€œlog transformâ€ the target.\n",
        "\n",
        "\n",
        "> Transforming the target variable (using the mathematical log function) into a tighter, more uniform space makes life easier for any [regression] model.\n",
        ">\n",
        "> The only problem is that, while easy to execute, understanding why taking the log of the target variable works and how it affects the training/testing process is intellectually challenging. You can skip this section for now, if you like, but just remember that this technique exists and check back here if needed in the future.\n",
        ">\n",
        "> Optimally, the distribution of prices would be a narrow â€œbell curveâ€ distribution without a tail. This would make predictions based upon average prices more accurate. We need a mathematical operation that transforms the widely-distributed target prices into a new space. The â€œprice in dollars spaceâ€ has a long right tail because of outliers and we want to squeeze that space into a new space that is normally distributed. More specifically, we need to shrink large values a lot and smaller values a little. That magic operation is called the logarithm or log for short. \n",
        ">\n",
        "> To make actual predictions, we have to take the exp of model predictions to get prices in dollars instead of log dollars. \n",
        ">\n",
        ">â€” Terence Parr & Jeremy Howard, [The Mechanics of Machine Learning, Chapter 5.5](https://mlbook.explained.ai/prep.html#logtarget)\n",
        "\n",
        "[Numpy has exponents and logarithms](https://docs.scipy.org/doc/numpy/reference/routines.math.html#exponents-and-logarithms). Your Python code could look like this:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "y_train_log = np.log1p(y_train)\n",
        "model.fit(X_train, y_train_log)\n",
        "y_pred_log = model.predict(X_val)\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "print(mean_absolute_error(y_val, y_pred))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z83puRQUSBoL"
      },
      "source": [
        "sns.distplot(y)\n",
        "plt.title('Original target, in the unit of US dollars');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-PK8BdxSBoO"
      },
      "source": [
        "y_log = np.log1p(y)\n",
        "sns.distplot(y_log)\n",
        "plt.title('Log-transformed target, in log-dollars');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7wMgpwTSBoP"
      },
      "source": [
        "y_untransformed = np.expm1(y_log)\n",
        "sns.distplot(y_untransformed)\n",
        "plt.title('Back to the original units');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMA4zESISBoR"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint. (If you haven't found a dataset yet, do that today. [Review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2) and choose your dataset.)\n",
        "\n",
        "Complete these tasks for your project, and document your decisions.\n",
        "\n",
        "- Choose your target. Which column in your tabular dataset will you predict?\n",
        "- Is your problem regression or classification?\n",
        "- How is your target distributed?\n",
        "    - Classification: How many classes? Are the classes imbalanced?\n",
        "    - Regression: Is the target right-skewed? If so, you may want to log transform the target.\n",
        "- Choose your evaluation metric(s).\n",
        "    - Classification: Is your majority class frequency >= 50% and < 70% ? If so, you can just use accuracy if you want. Outside that range, accuracy could be misleading. What evaluation metric will you choose, in addition to or instead of accuracy?\n",
        "    - Regression: Will you use mean absolute error, root mean squared error, R^2, or other regression metrics?\n",
        "- Choose which observations you will use to train, validate, and test your model.\n",
        "    - Are some observations outliers? Will you exclude them?\n",
        "    - Will you do a random split or a time-based split?\n",
        "- Begin to clean and explore your data.\n",
        "- Begin to choose which features, if any, to exclude. Would some features \"leak\" future information?\n",
        "\n",
        "Some students worry, ***what if my model isn't â€œgoodâ€?*** Then, [produce a detailed tribute to your wrongness. That is science!](https://twitter.com/nathanwpyle/status/1176860147223867393)"
      ]
    }
  ]
}